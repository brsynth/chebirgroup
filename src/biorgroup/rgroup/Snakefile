import ast
import pandas as pd
import shutil

from biorgroup._version import __app_name__
from biorgroup.utils.atomic import is_candidate

depot_dir = config["input_depot_str"]
input_chebi_csv = config["input_chebi_csv"]
input_pubchem_db = config["input_pubchem_db"]
output_dir = config["output_dir_str"]
search_timeout = config.get("parameter_search_timeout_int", "10")


df = pd.read_csv(input_chebi_csv)

chebi_ids = []
for ix, row in df.iterrows():
    if is_candidate(smiles=row["smiles"]):
        row_chebi_ids = ast.literal_eval(row["chebi"])
        chebi_id = row_chebi_ids[0]
        chebi_ids.append(chebi_id.replace("CHEBI:",""))

rule all:
    input:
        expand(os.path.join(output_dir, "refine", "chebi_{sample}.json"), sample=chebi_ids),
        os.path.join(output_dir, f"{__app_name__}.csv.gz"),

rule search:
    input:
        db = input_pubchem_db,
        chebi = input_chebi_csv,
    output:
        json = os.path.join(output_dir, "search", "chebi_{sample}.json")
    params:
        depot_dir = depot_dir,
        timeout = search_timeout,
    conda:
        "biorgroup"
    threads:
        6
    shell:
        "python -u {params.depot_dir}/search.py --input-chebi-csv {input.chebi} --input-pubchem-db {input.db} --parameter-chebi-int {wildcards.sample} --output {output.json} --input-thread-int {threads} --parameter-timeout-int {params.timeout}"

rule refine:
    input:
        json = os.path.join(output_dir, "search", "chebi_{sample}.json"),
        chebi = input_chebi_csv,
    output:
        json = os.path.join(output_dir, "refine", "chebi_{sample}.json")
    params:
        depot_dir = depot_dir,
        timeout = search_timeout,
    conda:
        "biorgroup"
    threads:
        6
    shell:
        "python -u {params.depot_dir}/refine.py --input-search-json {input.json} --output-refine-json {output.json} --input-chebi-csv {input.chebi} --parameter-chebi-int {wildcards.sample} --input-thread-int {threads} --parameter-timeout-int {params.timeout}"

rule aggregate:
    input:
        json = expand(rules.refine.output.json, sample=chebi_ids),
        chebi = input_chebi_csv,
    output:
        csv = os.path.join(output_dir, "chebis.csv.gz")
    params:
        depot_dir = depot_dir,
    conda:
        "biorgroup"
    shell:
        "python -u {params.depot_dir}/aggregate.py --input-chebi-csv {input.chebi} --input-refine-json {input.json} --output-chebi-csv {output.csv}"
