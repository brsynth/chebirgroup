import ast
import pandas as pd
import shutil

from chebirgroup.utils.atomic import is_candidate

input_chebi_csv = config["input_chebi_csv"]
input_pubchem_db = config["input_pubchem_db"]
output_dir = config["output_dir_str"]


df = pd.read_csv(input_chebi_csv)

chebi_ids = []
for ix, row in df.iterrows():
    if is_candidate(smiles=row["smiles_rhea"]):
        row_chebi_ids = ast.literal_eval(row["chebi"])
        chebi_id = row_chebi_ids[0]
        """
        chebi_basename = chebi_id.replace("CHEBI:", "chebi_") + ".txt"
        if not os.path.isfile(os.path.join("/work/user/ggricourt/rgroup/chebi/search", chebi_basename)):
            print("Chebi:", chebi_id, row_chebi_ids)
            for candidate in row_chebi_ids[1:]:
                chebi_basename_c = candidate.replace("CHEBI:", "chebi_") + ".txt"
                if os.path.isfile(os.path.join("/work/user/ggricourt/rgroup/chebi/search", chebi_basename_c)):
                    shutil.copyfile(os.path.join("/work/user/ggricourt/rgroup/chebi/search", chebi_basename_c), os.path.join("/work/user/ggricourt/rgroup/chebi/search", chebi_basename))
                    break
        """
        chebi_ids.append(chebi_id.replace("CHEBI:",""))

rule all:
    input:
        expand(os.path.join(output_dir, "refine", "chebi_{sample}.json"), sample=chebi_ids),
        os.path.join(output_dir, "chebis.csv.gz"),

rule search:
    input:
        db = input_pubchem_db,
        chebi = input_chebi_csv,
    output:
        txt = os.path.join(output_dir, "search", "chebi_{sample}.txt")
    conda:
        "chebirgroup"
    threads:
        6
    shell:
        "python -u /save/user/ggricourt/brsynth/chebirgroup/src/chebirgroup/rgroup/search.py --input-chebi-csv {input.chebi} --input-pubchem-db {input.db} --parameter-chebi-int {wildcards.sample} --output {output.txt} --input-thread-int {threads}"

rule refine:
    input:
        txt = os.path.join(output_dir, "search", "chebi_{sample}.txt"),
        chebi = input_chebi_csv,
    output:
        json = os.path.join(output_dir, "refine", "chebi_{sample}.json")
    conda:
        "chebirgroup"
    threads:
        6
    shell:
        "python -u /save/user/ggricourt/brsynth/chebirgroup/src/chebirgroup/rgroup/refine.py --input-search-txt {input.txt} --output-refine-json {output.json} --input-chebi-csv {input.chebi} --parameter-chebi-int {wildcards.sample} --input-thread-int {threads}"

rule aggregate:
    input:
        json = expand(rules.refine.output.json, sample=chebi_ids),
        chebi = input_chebi_csv,
    output:
        csv = os.path.join(output_dir, "chebis.csv.gz")
    conda:
        "chebirgroup"
    shell:
        "python -u /save/user/ggricourt/brsynth/chebirgroup/src/chebirgroup/rgroup/aggregate.py --input-chebi-csv {input.chebi} --input-refine-json {input.json} --output-chebi-csv {output.csv}"
